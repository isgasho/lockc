<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>lockc Documentation</title>
        <meta name="robots" content="noindex" />
        <!-- Custom HTML head -->
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="**lockc** is open source software for providing MAC (Mandatory Access Control) implemented in Rust">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">
        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">
        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="index.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="containers-do-not-contain.html"><strong aria-hidden="true">2.</strong> Containers do not contain</a></li><li class="chapter-item expanded "><a href="architecture.html"><strong aria-hidden="true">3.</strong> Architecture</a></li><li class="chapter-item expanded "><a href="configuration.html"><strong aria-hidden="true">4.</strong> Getting started</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="build/index.html"><strong aria-hidden="true">4.1.</strong> Build</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="build/containerized.html"><strong aria-hidden="true">4.1.1.</strong> Containerized</a></li><li class="chapter-item expanded "><a href="build/meson.html"><strong aria-hidden="true">4.1.2.</strong> Meson</a></li></ol></li><li class="chapter-item expanded "><a href="use/index.html"><strong aria-hidden="true">4.2.</strong> Use</a></li><li class="chapter-item expanded "><a href="terraform/index.html"><strong aria-hidden="true">4.3.</strong> Provision</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="terraform/base-image.html"><strong aria-hidden="true">4.3.1.</strong> Base image</a></li><li class="chapter-item expanded "><a href="terraform/custom-kernel.html"><strong aria-hidden="true">4.3.2.</strong> (Optional) Custom kernel</a></li><li class="chapter-item expanded "><a href="terraform/libvirt.html"><strong aria-hidden="true">4.3.3.</strong> Use libvirt</a></li><li class="chapter-item expanded "><a href="terraform/openstack.html"><strong aria-hidden="true">4.3.4.</strong> Use OpenStack</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="policies/index.html"><strong aria-hidden="true">5.</strong> Policies</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="policies/mount.html"><strong aria-hidden="true">5.1.</strong> Mount</a></li><li class="chapter-item expanded "><a href="policies/syslog.html"><strong aria-hidden="true">5.2.</strong> Syslog</a></li></ol></li><li class="chapter-item expanded "><a href="demos/index.html"><strong aria-hidden="true">6.</strong> Demos</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="demos/mount.html"><strong aria-hidden="true">6.1.</strong> Mount</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">lockc Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p><strong>lockc</strong> is open source software for providing MAC (Mandatory Access Control)
type of security audit for container workloads.</p>
<p>The main reason why <strong>lockc</strong> exists is that <strong>containers do not contain</strong>.
Containers are not as secure and isolated as VMs. By default, they expose
a lot of information about host OS and provide ways to &quot;break out&quot; from the
container. <strong>lockc</strong> aims to provide more isolation to containers and make them
more secure.</p>
<p>The <a href="containers-do-not-contain.html">Containers do not contain</a> documentation
section explains why we mean by that phrase and what kind of behavior we want
to restrict with <strong>lockc</strong>.</p>
<p>The main technology behind lockc is <a href="https://ebpf.io/">eBPF</a> - to be more
precise, its ability to attach to <a href="https://www.kernel.org/doc/html/latest/bpf/bpf_lsm.html">LSM hooks</a></p>
<p>Please note that currently lockc is an experimental project, not meant for
production environments. Currently we don't publish any official binaries or
packages to use, except of a Rust crate. Currently the most convenient way
to use it is to use the source code and follow the guide.</p>
<h2 id="contributing"><a class="header" href="#contributing">Contributing</a></h2>
<p>If you need help or want to talk with contributors, please come chat with
us on <code>#lockc</code> channel on the <a href="https://discord.gg/799cmsYB4q">Rust Cloud Native Discord server</a>.</p>
<p>You can find the source code on <a href="https://github.com/rancher-sandbox/lockc">GitHub</a>
and issues and feature requests can be posted on the
<a href="https://github.com/rancher-sandbox/lockc/issues">GitHub issue tracker</a>.
<strong>lockc</strong> relies on the community to fix bugs and add features: if you'd like
to contribute, please read the <a href="https://github.com/rancher-sandbox/lockc/blob/master/CONTRIBUTING.md">CONTRIBUTING</a>
guide and consider opening <a href="https://github.com/rancher-sandbox/lockc/pulls">pull request</a>.</p>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p><strong>lockc's</strong> userspace part is licensed under <a href="https://github.com/rancher-sandbox/lockc/blob/main/LICENSE">Apache License, version 2.0</a>.</p>
<p>eBPF programs inside <a href="https://github.com/rancher-sandbox/lockc/tree/main/src/bpf">src/bpf directory</a>
are licensed under <a href="https://github.com/rancher-sandbox/lockc/blob/main/src/bpf/LICENSE">GNU General Public License, version 2</a>.</p>
<p>Documentation is licensed under <a href="https://www.mozilla.org/MPL/2.0/">Mozilla Public License v2.0</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="containers-to-not-contain"><a class="header" href="#containers-to-not-contain">Containers to not contain</a></h1>
<p>Many people assume that containers:</p>
<ul>
<li>provide the same or similar isolation to virtual machines</li>
<li>protects the host system</li>
<li>sandboxes applications</li>
</ul>
<p>While all the points except the first one are partially true, some parts of the
host filesystems are still exposed by default to containers and there are ways to
gain full access.</p>
<p>This section highlights and explains problematic exploitation possibilities
that <strong>lockc</strong> aims to fix via policies.</p>
<p>Please note that as <strong>lockc</strong> is still in early development stage, it doesn't
protect against all examples provided at this time. However, covering them all
is in the roadmap.</p>
<p>The goal of <strong>lockc</strong> is to eventually prevent any of those examples to be done
by a regular user. Following some examples as root by explicitly choosing the
<em>privileged</em> policy level in lockc is going to be still allowed. However, it is
is discouraged to use the <em>priviliged</em> level for containers which are not part
of Kubernetes infra (CNI plugins, operators, network meshes etc.). We might
still consider restricting some of behaviors even for <em>privileged</em> (i.e. it's
probably hard to justify <code>chroot</code> inside containers under any ciricumstance).</p>
<h2 id="not-everything-is-namespaced"><a class="header" href="#not-everything-is-namespaced">Not everything is namespaced</a></h2>
<p>Despite the fact that containers come with their own rootfs, some parts of the
filesystem are <strong>not namespaced</strong>, which means that the content of some
directories is <strong>exactly the same as on the host OS</strong>. Examples:</p>
<ul>
<li>Kernel filesystems under <em>/sys</em></li>
<li><em>/proc/bus</em></li>
<li><em>/proc/irq</em></li>
<li><em>/proc/sys</em></li>
<li><em>/proc/sysrq-trigger</em></li>
</ul>
<p>For non-privileged containers, the content of those directories is read-only.
However, privileged containers can write to them. In both cases, we think that
even exposing many of those directories without write access is unnecessary
for regular containers.</p>
<p>To show some more concrete examples, access to those directories can allow to:</p>
<ul>
<li>Check and change GPU settings</li>
</ul>
<pre><code class="language-bash">❯ docker run --rm -it opensuse/tumbleweed:latest bash
f4891490a2f3:/ # cat /sys/class/drm/card0/device/power_dpm_force_performance_level
auto
f4891490a2f3:/ # exit
❯ docker run --rm --privileged -it opensuse/tumbleweed:latest bash
bad479286479:/ # echo high &gt; /sys/class/drm/card0/device/power_dpm_force_performance_level
bad479286479:/ # cat /sys/class/drm/card0/device/power_dpm_force_performance_level
high
bad479286479:/ # exit
❯ cat /sys/class/drm/card0/device/power_dpm_force_performance_level
high
</code></pre>
<ul>
<li>look at the host OS filesystem metadata</li>
</ul>
<pre><code class="language-bash">❯ docker run --rm -it opensuse/tumbleweed:latest bash
0d35122d08f9:~ # ls /sys/fs/btrfs/a8222a26-d11e-4276-9c38-9df2812cead2/
allocation  bdi  bg_reclaim_threshold  checksum  clone_alignment  devices  devinfo  exclusive_operation  features  generation  label  metadata_uuid  nodesize  qgroups  quota_override  read_policy  sectorsize
</code></pre>
<ul>
<li>use fdisk in a privileged container</li>
</ul>
<pre><code class="language-bash">❯ docker run --rm -it --privileged registry.opensuse.org/opensuse/toolbox:latest bash
8b71e0119552:/ # fdisk -l
Disk /dev/nvme0n1: 1.82 TiB, 2000398934016 bytes, 3907029168 sectors
Disk model: Samsung SSD 970 EVO Plus 2TB
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: gpt
Disk identifier: 8EEBDAB8-F965-4BA0-918A-2671BC67117C

Device           Start        End    Sectors  Size Type
/dev/nvme0n1p1    2048    1026047    1024000  500M EFI System
/dev/nvme0n1p2 1026048 3907029134 3906003087  1.8T Linux filesystem
</code></pre>
<h2 id="host-mounts"><a class="header" href="#host-mounts">Host mounts</a></h2>
<p>Container engines allow to bind mount any directory from the host. When using
local, non-clusterized container engines (docker, podman etc.) there are no
restrictions about what can be mounted. In case of Docker, anyone who has an
access to the socket (usually a member of <code>docker</code> group) can mount anything.</p>
<p>That gives every member of the <code>docker</code> group an access to the host OS as root:</p>
<pre><code class="language-bash">❯ docker run --rm --privileged -it -v /:/rootfs opensuse/tumbleweed:latest bash
efa4f6e0529a:/ # chroot /rootfs
sh-4.4#
</code></pre>
<p>The <code>chroot</code> works without <code>--privileged</code> as well:</p>
<pre><code class="language-bash">❯ docker run --rm -it -v /:/rootfs opensuse/tumbleweed:latest bash
abb67212044d:/ # chroot /rootfs
sh-4.4#
</code></pre>
<p>The other approach is to mount a Docker socket. The image used here is <code>docker</code>
which is the official image with Docker binaries installed. After starting the
first container, we are able to list containers running on the host. Then, we
are able to run another container - from inside the first one - which is
mounting directories from the host</p>
<pre><code class="language-bash">❯ docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock docker sh
/ # docker ps
CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS     NAMES
066811b60d69   docker    &quot;docker-entrypoint.s…&quot;   5 seconds ago   Up 5 seconds             suspicious_liskov
/ # docker run --rm --privileged -it opensuse/tumbleweed:latest bash
fcb94c1d3af6:/ # exit
/ # docker run --rm --privileged -it -v /:/rootfs opensuse/tumbleweed:latest bash
54b08e30fd9e:/ # chroot /rootfs
sh-4.4# cat /etc/os-release
NAME=&quot;openSUSE Leap&quot;
VERSION=&quot;15.3&quot;
ID=&quot;opensuse-leap&quot;
ID_LIKE=&quot;suse opensuse&quot;
VERSION_ID=&quot;15.3&quot;
PRETTY_NAME=&quot;openSUSE Leap 15.3&quot;
ANSI_COLOR=&quot;0;32&quot;
CPE_NAME=&quot;cpe:/o:opensuse:leap:15.3&quot;
BUG_REPORT_URL=&quot;https://bugs.opensuse.org&quot;
HOME_URL=&quot;https://www.opensuse.org/&quot;
</code></pre>
<p>Notice the difference between Linux distibution versions. The second container
image we used is <em>openSUSE Tumbleweed</em>, but the host is running
<em>openSUSE Leap 15.3</em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="architecture"><a class="header" href="#architecture">Architecture</a></h1>
<p>The project consists of 3 parts:</p>
<ul>
<li>the set of BPF programs (written in C)
<ul>
<li>programs for monitoring processes, which detects whether new processes
are running inside any container, which means applying policies on them</li>
<li>programs attached to particular LSM hooks, which allow or deny actions
based on the policy applied to the container (currently all containers have
the <code>baseline</code> policy applied, the mechanism of differentiating between
policies per container/pod is yet to be implemented)</li>
</ul>
</li>
<li><strong>lockcd</strong> - the userspace program (written in Rust)
<ul>
<li>loads the BPF programs into the kernel, pins them in BPFFS</li>
<li>in future, it's going to serve as the configuration manager and log
collector</li>
</ul>
</li>
<li><strong>lockc-runc-wrapper</strong> - a wraper for runc which registers new containers
and determines which policy should be applied on a container</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting started</a></h1>
<ul>
<li><a href="build/README.html">Build</a> - How to build lockc from the sources</li>
<li><a href="use/README.html">Use</a> - Configuring and using lockc locally</li>
<li><a href="terraform/README.html">Provision</a> - :Using Terraform for provisioning lockc</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="building-lockc"><a class="header" href="#building-lockc">Building lockc</a></h2>
<p>The first step to try out lockc is to build it. There are two ways to do
that:</p>
<ul>
<li><strong><a href="build/containerized.html">Containerized</a></strong> - build project binaries within container</li>
<li><strong><a href="build/meson.html">Meson</a></strong> - build binaries with Meson</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h3 id="containerized-build"><a class="header" href="#containerized-build">Containerized build</a></h3>
<p>One option for building lockc is using the <code>containerized-build.sh</code> script
to perform the build inside container, without installing needed
dependencies on the host system.</p>
<p>This guide assumes that you have <code>docker</code> or any other container engine
installed.</p>
<p>The build can be performed by running the following command:</p>
<pre><code class="language-bash">./containerized-build.sh build
</code></pre>
<p>or simply:</p>
<pre><code class="language-bash">./containerized-build.sh
</code></pre>
<p><code>build</code> is the default subcommand of <code>containerized-build</code>. There are
several other subcommands:</p>
<pre><code class="language-bash">$ ./containerized-build.sh help
Usage: containerized-build.sh &lt;subcommand&gt;

Subcommands:
    gen        Compile BPF programs and generate BPF CO-RE skeleton
    build      Build lockc
    install    Install lockc
    fmt        Autoformat code
    lint       Code analysis
    help       Show help information
</code></pre>
<p>For following this guide, using the <code>build</code> subcommand is enough.</p>
<p><code>./containerized-build.sh install</code> can be used to install
lockc in your host system, which by default means directories like
<code>/usr/bin</code>, <code>/etc</code>. Target directories can be customized by <code>DESTDIR</code>,
<code>PREFIX</code>, <code>BINDIR</code>, <code>UNITDIR</code> and <code>SYSCONFDIR</code> environment variables.</p>
<p><code>build</code> should result in binaries produced in the <code>build/</code> directory:</p>
<pre><code class="language-bash">$ ls build/
lockcd  lockc-runc-wrapper
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h3 id="meson"><a class="header" href="#meson">Meson</a></h3>
<p>If you are comfortable with installing all dependencies on your host
system, you need to install the following software:</p>
<ul>
<li>meson</li>
<li>rust, cargo</li>
<li>llvm, clang</li>
<li>libbpf</li>
<li>bpftool</li>
</ul>
<p>Build can be performed by the following commands:</p>
<pre><code class="language-bash">CC=clang meson build
cd build
meson compile
</code></pre>
<p>Installation can be perfomed by:</p>
<pre><code class="language-bash">meson install
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="using-lockc-locally"><a class="header" href="#using-lockc-locally">Using lockc locally</a></h2>
<p>lockc can be used on the local system if you want to secure your local
container engine (docker, podman).</p>
<p>BPF programs can be loaded by executing <code>lockcd</code>:</p>
<p>First, we need to load BPF programs by running lockcd. That can be done
by the following command:</p>
<pre><code class="language-bash">sudo ./build/src/lockcd
</code></pre>
<p>If you have <code>bpftool</code> available on your host, you canm check whether lockc
BPF programs are running. The correct output should look similar to:</p>
<pre><code class="language-bash">sudo bpftool prog
[...]
25910: tracing  name sched_process_f  tag 3a6a6e4defce95ab  gpl
        loaded_at 2021-06-02T16:52:57+0200  uid 0
        xlated 2160B  jited 1137B  memlock 4096B  map_ids 14781,14782,14783
        btf_id 18711
25911: lsm  name clone_audit  tag fc30a5b3e6a4610b  gpl
        loaded_at 2021-06-02T16:52:57+0200  uid 0
        xlated 2280B  jited 1196B  memlock 4096B  map_ids 14781,14782,14783
        btf_id 18711
25912: lsm  name syslog_audit  tag 2cdd93e75fa0e936  gpl
        loaded_at 2021-06-02T16:52:57+0200  uid 0
        xlated 816B  jited 458B  memlock 4096B  map_ids 14783,14782
        btf_id 18711
</code></pre>
<p>To check if containers get &quot;hardened&quot; by lockc, check if you are able to
see the kernel logs from inside the container wrapped by <strong>lockc-runc-wrapper</strong>.
Example:</p>
<pre><code class="language-bash">podman --runtime ./out/lockc-runc-wrapper run -ti --rm registry.opensuse.org/opensuse/toolbox:latest
a135dbc3ef08:/ # dmesg
dmesg: read kernel buffer failed: Operation not permitted
</code></pre>
<p>That error means that lockc works, applied the <em>baseline</em> policy on a new
container and prevented containerized processes from accessing kernel logs.</p>
<p>If<code>dmesg</code> ran successfully and shows the kernel logs, it means that something
went wrong and lockc is not working properly.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="terraform"><a class="header" href="#terraform">Terraform</a></h2>
<p>There is also a possibility to run lockc in virtual machines with
Kubernetes.</p>
<p>In order to do that, ensure that you have the following software installed:</p>
<ul>
<li>libvirt</li>
<li>guestfs-tools</li>
</ul>
<p>Then we can proceed with following steps:</p>
<ul>
<li><strong><a href="terraform/base-image.html">Base image</a></strong> - The first step is to build the VM image</li>
<li><strong><a href="terraform/custom-kernel.html">Custom kernel</a></strong> <em>Optional</em> - building the image with a custom kernel</li>
<li><strong><a href="terraform/libvirt.html">Use libvirt</a></strong> - Configure and start VMs in libvirt environment</li>
<li><strong><a href="terraform/openstack.html">Use OpenStack</a></strong> - Starting VMs in OpenStack environment</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h4 id="building-the-base-image"><a class="header" href="#building-the-base-image">Building the base image</a></h4>
<p>The first step is to build the VM image.</p>
<pre><code class="language-bash">cd contrib/guestfs
./build
</code></pre>
<p>If the script ran successfully, <code>lockc-base.qcow2</code> file should be present.
It cointains the base VM image which will be used by Terraform.</p>
<div style="break-before: page; page-break-before: always;"></div><h4 id="optional-building-the-image-with-a-custom-kernel"><a class="header" href="#optional-building-the-image-with-a-custom-kernel">(Optional) building the image with a custom kernel</a></h4>
<p>The <code>build.sh</code> script can be also used to create a VM image with a
custom kernel if there is a need for kernel testing. You can optionally
provide a path to your kernel source tree. Please note that the kernel
should be already build on the host with <code>make</code>. Our guestfs scripts do
only <code>make modules_install install</code> to install the kernel image and
modules inside a VM. Installing the custom kernel is enabled by using
the <code>CUSTOM_KERNEL</code> environment variable. Its value has to be set to
<code>true</code>. By default, the script assumes that your kernel tree is in
<code>~/linux</code> directory. You can provide a custom path by another
environment variable - <code>KERNEL_SOURCE</code>. Examples of usage:</p>
<pre><code class="language-bash">CUSTOM_KERNEL=true ./build.sh
CUSTOM_KERNEL=true KERNEL_SOURCE=${HOME}/my-git-repos/linux ./build.sh
</code></pre>
<p>If you already used <code>build.sh</code> once and you would like to inject a
custom kernel into already build qcow2 image, there is a separate script</p>
<ul>
<li><code>reinstall-custom-kernel.sh</code>. It takes an optional <code>KERNEL_SOURCE</code>
environment variable. Examples of usage:</li>
</ul>
<pre><code class="language-bash">./reinstall-custom-kernel.sh
KERNEL_SOURCE=${HOME}/my-git-repos/linux ./reinstall-custom-kernel.sh
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h4 id="configure-libvirt"><a class="header" href="#configure-libvirt">Configure libvirt</a></h4>
<p>VMs which we are going to run are using 9p to mount the source tree. To
ensure that those mounts are going to work correctly, open the
<code>/etc/libvirt/qemu.conf</code> file and ensure that the following options
are present there:</p>
<pre><code class="language-bash">user = &quot;root&quot;
group = &quot;root&quot;
dynamic_ownership = 0
</code></pre>
<p>If you had to edit the configuration, save the file and restart libvirt:</p>
<pre><code class="language-bash">sudo systemctl restart libvirtd
</code></pre>
<h4 id="running-vms"><a class="header" href="#running-vms">Running VMs</a></h4>
<p>Now it's time to prepare Terraform environment.</p>
<pre><code class="language-bash">cd contrib/terraform/libvirt
cp terraform.tfvars.json.example terraform.tfvars.json
</code></pre>
<p>After that, open the <code>terraform.tfvars.json</code> file with your favorite text
editor. The only setting which you really need to change is
<code>authorized_keys</code>. Please paste your public SSH key there. Otherwise,
connecting to VMs with SSH will be impossible.</p>
<p>Initialize the environment with:</p>
<pre><code class="language-bash">terraform init
</code></pre>
<p>And then start the VMs:</p>
<pre><code class="language-bash">terraform apply
</code></pre>
<p>Terraform finished successfully, you should see the output with IP
addresses of virtual machines, like:</p>
<pre><code class="language-bash">ip_control_planes = {
  &quot;lockc-control-plane-0&quot; = &quot;10.16.0.225&quot;
}
</code></pre>
<p>You can simply ssh to them using the <code>opensuse</code> user:</p>
<pre><code class="language-bash">ssh opensuse@10.16.0.255
</code></pre>
<p>Inside the VM we can check whether Kubernetes is running:</p>
<pre><code class="language-bash"># kubectl get pods -A
NAMESPACE     NAME                                            READY
STATUS    RESTARTS   AGE
kube-system   coredns-78fcd69978-lvshz                        0/1
Running   0          7s
kube-system   coredns-78fcd69978-q874s                        0/1
Running   0          7s
kube-system   etcd-lockc-control-plane-0                      1/1
Running   0          11s
kube-system   kube-apiserver-lockc-control-plane-0            1/1
Running   0          10s
kube-system   kube-controller-manager-lockc-control-plane-0   1/1
Running   0          11s
kube-system   kube-proxy-p7nrd                                1/1
Running   0          7s
kube-system   kube-scheduler-lockc-control-plane-0            1/1
Running   0          11s
</code></pre>
<p>And whether lockc is running. The main service can be checked by:</p>
<pre><code class="language-bash">systemctl status lockcd
</code></pre>
<p>We can check also whether lockc's BPF programs are running:</p>
<pre><code class="language-bash"># bpftool prog list
35: tracing  name sched_process_f  tag b3c2c2a08effc879  gpl
      loaded_at 2021-08-10T12:23:55+0000  uid 0
      xlated 1528B  jited 869B  memlock 4096B  map_ids 3,2
      btf_id 95
36: lsm  name clone_audit  tag 33a5e8a5da485fd4  gpl
      loaded_at 2021-08-10T12:23:55+0000  uid 0
      xlated 1600B  jited 899B  memlock 4096B  map_ids 3,2
      btf_id 95
37: lsm  name syslog_audit  tag 80d655f557922055  gpl
      loaded_at 2021-08-10T12:23:55+0000  uid 0
      xlated 1264B  jited 714B  memlock 4096B  map_ids 3,2
      btf_id 95
[...]
</code></pre>
<p>And whether it registers containers. Directories inside
<code>/sys/fs/bpf/lockc</code> represent timestamps of lockcd launch, so it will be
different than in the following example.</p>
<pre><code class="language-bash"># bpftool map dump pinned /sys/fs/bpf/lockc/1628598193/map_containers
[{
        &quot;key&quot;: 4506,
        &quot;value&quot;: {
            &quot;policy_level&quot;: &quot;POLICY_LEVEL_PRIVILEGED&quot;
        }
[...]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<p>These terraform definitions are going to create the whole
cluster on top of openstack.</p>
<h2 id="deployment"><a class="header" href="#deployment">Deployment</a></h2>
<p>Make sure to download an openrc file from your OpenStack instance, e.g.:</p>
<p><code>https://engcloud.prv.suse.net/project/api_access/openrc/</code></p>
<p>and source it:</p>
<pre><code class="language-sh">source container-openrc.sh
</code></pre>
<p>Also make sure to have your ssh key within OpenStack, by adding your key to the
key_pairs first.</p>
<p>Upload <code>lockc</code> base image build with guestfs.</p>
<pre><code class="language-sh">openstack image create lockc-`date +%F` --disk-format qcow2 --file ./lockc-base.qcow2
</code></pre>
<p>Once you perform a <a href="terraform/openstack.html#Customization">Customization</a> you can use <code>terraform</code> to deploy the cluster:</p>
<pre><code class="language-sh">terraform init
terraform validate
terraform apply
</code></pre>
<h2 id="machine-access"><a class="header" href="#machine-access">Machine access</a></h2>
<p>It is important to have your public ssh key within the <code>authorized_keys</code>,
this is done by <code>cloud-init</code> through a terraform variable called <code>authorized_keys</code>.</p>
<p>All the instances have a <code>root</code> and <code>opensuse</code> user. The normal 'opensuse' user user can
perform <code>sudo</code> without specifying a password.</p>
<p>Neither root nor the normal <code>opensuse</code> user will have password. Terraform
is using SSH key-based authentication. You can always set a password after the
creation of the machines using <code>sudo passwd opensuse</code> (for normal user) or <code>sudo passwd</code> (for root).</p>
<h2 id="load-balancer"><a class="header" href="#load-balancer">Load balancer</a></h2>
<p>The kubernetes api-server instances running inside of the cluster are
exposed by a load balancer managed by OpenStack.</p>
<h2 id="customization"><a class="header" href="#customization">Customization</a></h2>
<p>Copy the <code>terraform.tfvars.example</code> to <code>terraform.tfvars</code> and
provide reasonable values.</p>
<h2 id="variables"><a class="header" href="#variables">Variables</a></h2>
<p><code>image_name</code> - Name of the image to use<br />
<code>internal_net</code> - Name of the internal network to be created<br />
<code>stack_name</code> - Identifier to make all your resources unique and avoid clashes with other users of this terraform project<br />
<code>authorized_keys</code> - A list of ssh public keys that will be installed on all nodes<br />
<code>repositories</code> - Additional repositories that will be added on all nodes<br />
<code>packages</code> - Additional packages that will be installed on all nodes\</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="policies"><a class="header" href="#policies">Policies</a></h1>
<p>lockc provides three policy levels for containers:</p>
<ul>
<li><strong>baseline</strong> - meant for regular applications</li>
<li><strong>restricted</strong> - meant for applications for which we need to be more cautious
and secure them more stricly</li>
<li><strong>privileged</strong> - meant for part of the infrastructure which can have full
access to host resources - i.e. CNI plugins in Kubernetes</li>
</ul>
<p>The default policy level is <strong>baseline</strong>. The policy level can be changed by
the <code>pod-security.kubernetes.io/enforce</code> label on the <strong>namespace</strong> which
the container is running in. We make an exception for the <em>kube-system</em>
namespace for which the <strong>privileged</strong> policy is applied by default.</p>
<p>For now there is no possibility to apply policy levels on local container
engines (Docker, containerd, podman), but such feature is planned in the
future.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="mount-policies"><a class="header" href="#mount-policies">Mount policies</a></h2>
<p>lockc comes with the following policies about bind mounts from host filesystem
to containers (via <code>-v</code> option) for each policy level:</p>
<ul>
<li><strong>baseline</strong> - allow bind mounting from inside <code>/home</code> and <code>/var/data</code>.</li>
<li><strong>restricted</strong> - does not allow any bind mounts from host</li>
<li><strong>privileged</strong> - no restrictions, everything can be bind mounted</li>
</ul>
<p>The <strong>baseline</strong> behavior in lockc is slightly different than in the Kubernetes
Pod Security Admission controller, which disallows all host mounts for baseline
containers as well as for restricted. The motivation behind allowing <code>/home</code>
and <code>/var/data</code> by lockc is that they are often used in local container engines
(Docker, podman) for reasons like:</p>
<ul>
<li>mounting the source code to build or check</li>
<li>storing database content on the host for local development</li>
</ul>
<p>By default, with the <strong>baseline</strong> policy level, this is a good example of
not allowed behavior:</p>
<pre><code class="language-bash"># podman --runtime $(pwd)/build/src/lockc-runc-wrapper run -ti -v /:/rootfs --rm registry.opensuse.org/opensuse/toolbox:latest
Error: container create failed (no logs from conmon): EOF
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="syslog"><a class="header" href="#syslog">Syslog</a></h2>
<p>lockc comes with the following policies about access to the kernel message ring
buffer for each policy level:</p>
<ul>
<li><strong>baseline</strong> - not allowed</li>
<li><strong>restricted</strong> - not allowed</li>
<li><strong>privileged</strong> - allowed</li>
</ul>
<p>By default, with the <strong>baseline</strong> policy level, checking the kernel logs from
the container is not allowed:</p>
<pre><code class="language-bash"># podman --runtime $(pwd)/build/src/lockc-runc-wrapper run -ti --rm registry.opensuse.org/opensuse/toolbox:latest
b10f9fa4a385:/ # dmesg
dmesg: read kernel buffer failed: Operation not permitted
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="demos"><a class="header" href="#demos">Demos</a></h1>
<p>This section of the book contains demos.</p>
<ul>
<li><a href="demos/mount.html">Mount</a> - mount policies</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="mount-policies-1"><a class="header" href="#mount-policies-1">Mount policies</a></h2>
<h3 id="kubernetes"><a class="header" href="#kubernetes">Kubernetes</a></h3>
<p>The following demo shows mount policies being enforced on Kubernetes pods.</p>
<p>YAML files can be found <a href="https://github.com/rancher-sandbox/lockc/tree/main/examples/kubernetes">here</a>.</p>
<p>The policy violations in <a href="https://github.com/rancher-sandbox/lockc/tree/main/examples/kubernetes/deployments-should-fail.yaml">deployments-should-fail.yaml</a>
file are:</p>
<ul>
<li><em>nginx-restricted-fail</em> deployment trying to make a host mount while having a
<strong>restricted</strong> policy</li>
<li><em>bpf-default-fail</em> and <em>bpf-baseline-fail</em> deployment trying to mount
<code>/sys/fs/bpf</code> while having a <strong>baseline</strong> policy</li>
<li><em>bpf-restricted-fail</em> trying to mount <code>/sys/fs/bpf</code> while having a
<strong>restricted</strong> policy.</li>
</ul>
<p><a href="https://asciinema.org/a/sUxMMB5BKkJzlF1jP6k8Bxab3"><img src="https://asciinema.org/a/sUxMMB5BKkJzlF1jP6k8Bxab3.svg" alt="asciicast" /></a></p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
            </nav>

        </div>

        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
    </body>
</html>
